[tool.poetry]
name = "inference-llm"
version = "0.1.0"
description = "A dockerized inference of LLM"
authors = ["AbinavRavi <abinav.ravi@tum.de>"]
readme = "README.md"
packages = [{include = "inference_llm"}]

[tool.poetry.dependencies]
python = "^3.10"
fastapi = "^0.101.0"
pydantic = "^2.1.1"
torch = "^2.0.1"
transformers = "^4.31.0"
nvidia-cublas-cu11 = { version = "11.10.3.66", platform = 'linux' }
nvidia-cuda-cupti-cu11 = { version = "11.7.101", platform = 'linux' }
nvidia-cuda-nvrtc-cu11 = { version = "11.7.99", platform = 'linux' }
nvidia-cuda-runtime-cu11 = { version = "11.7.99", platform = 'linux' }
nvidia-cudnn-cu11 = { version = "8.5.0.96", platform = 'linux' }
nvidia-cufft-cu11 = { version = "10.9.0.58", platform = 'linux' }
nvidia-curand-cu11 = { version = "10.2.10.91", platform = 'linux' }
nvidia-cusolver-cu11 = { version = "11.4.0.1", platform = 'linux' }
nvidia-cusparse-cu11 = { version = "11.7.4.91", platform = 'linux' }
nvidia-nccl-cu11 = { version = "2.14.3", platform = 'linux' }
nvidia-nvtx-cu11 = { version = "11.7.91", platform = 'linux' }
triton = { version = "2.0.0", platform = 'linux' }
einops = "^0.6.1"
requests = "^2.31.0"


[tool.poetry.group.dev.dependencies]
black = "^23.7.0"
bandit = "^1.7.5"
ruff = "^0.0.282"
flake8 = "^6.1.0"
radon = "^6.0.1"
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
pre-commit = "^3.3.3"

[tool.mypy]
ignore_missing_imports = true
exclude = ["huggingface_hub"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
